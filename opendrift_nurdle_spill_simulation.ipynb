{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "\n",
    "# NetCDF / data handling\n",
    "import xarray as xr\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Copernicus Marine Toolbox\n",
    "from copernicusmarine import login, subset\n",
    "\n",
    "# Time series modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# OpenDrift simulation\n",
    "from opendrift.models.oceandrift import OceanDrift\n",
    "from opendrift.readers.reader_netCDF_CF_generic import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e94a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Fetch credentials\n",
    "username = os.getenv(\"CMDS_USERNAME\")\n",
    "password = os.getenv(\"CMDS_PASSWORD\")\n",
    "\n",
    "if not username or not password:\n",
    "    raise ValueError(\"CMDS_USERNAME or CMDS_PASSWORD not set in .env\")\n",
    "\n",
    "# Authenticate with Copernicus Marine\n",
    "login(username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf78945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cmems(year, output_dir,\n",
    "                   min_lon=160, max_lon=180, min_lat=-77, max_lat=-72,\n",
    "                   start_depth=0, end_depth=1):\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    from copernicusmarine import subset\n",
    "    import xarray as xr\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = f\"copernicus_currents_{year}.nc\"\n",
    "    output_path = os.path.join(output_dir, output_file)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"✅ Already exists: {output_path}\")\n",
    "        return\n",
    "\n",
    "    # Dataset selection\n",
    "    if year <= 2020:\n",
    "        dataset_id = \"cmems_mod_glo_phy_my_0.083deg_P1D-m\"\n",
    "    else:\n",
    "        dataset_id = \"cmems_mod_glo_phy-cur_anfc_0.083deg_P1D-m\"\n",
    "    variables = ['uo', 'vo']\n",
    "\n",
    "    if year == 2025:\n",
    "        # Special case: only download January 2025\n",
    "        try:\n",
    "            print(f\"⬇️ Downloading January {year} only...\")\n",
    "            subset(\n",
    "                dataset_id=dataset_id,\n",
    "                minimum_longitude=min_lon,\n",
    "                maximum_longitude=max_lon,\n",
    "                minimum_latitude=min_lat,\n",
    "                maximum_latitude=max_lat,\n",
    "                minimum_depth=start_depth,\n",
    "                maximum_depth=end_depth,\n",
    "                start_datetime=f\"{year}-01-01 00:00:00\",\n",
    "                end_datetime=f\"{year}-01-31 23:59:59\",\n",
    "                variables=variables,\n",
    "                output_directory=output_dir,\n",
    "                output_filename=output_file,\n",
    "                netcdf3_compatible=True\n",
    "            )\n",
    "            print(f\"✅ Saved: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed for January 2025: {e}\")\n",
    "        return\n",
    "\n",
    "    # Normal case: download both December and January\n",
    "    dec_file = os.path.join(output_dir, f\"tmp_{year}_dec.nc\")\n",
    "    jan_file = os.path.join(output_dir, f\"tmp_{year}_jan.nc\")\n",
    "\n",
    "    success_dec = False\n",
    "    success_jan = False\n",
    "\n",
    "    try:\n",
    "        print(f\"⬇️ Downloading December {year}...\")\n",
    "        subset(\n",
    "            dataset_id=dataset_id,\n",
    "            minimum_longitude=min_lon,\n",
    "            maximum_longitude=max_lon,\n",
    "            minimum_latitude=min_lat,\n",
    "            maximum_latitude=max_lat,\n",
    "            minimum_depth=start_depth,\n",
    "            maximum_depth=end_depth,\n",
    "            start_datetime=f\"{year}-12-01 00:00:00\",\n",
    "            end_datetime=f\"{year}-12-31 23:59:59\",\n",
    "            variables=variables,\n",
    "            output_directory=output_dir,\n",
    "            output_filename=os.path.basename(dec_file),\n",
    "            netcdf3_compatible=True\n",
    "        )\n",
    "        success_dec = os.path.exists(dec_file)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ December {year} failed: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"⬇️ Downloading January {year + 1}...\")\n",
    "        subset(\n",
    "            dataset_id=dataset_id,\n",
    "            minimum_longitude=min_lon,\n",
    "            maximum_longitude=max_lon,\n",
    "            minimum_latitude=min_lat,\n",
    "            maximum_latitude=max_lat,\n",
    "            minimum_depth=start_depth,\n",
    "            maximum_depth=end_depth,\n",
    "            start_datetime=f\"{year + 1}-01-01 00:00:00\",\n",
    "            end_datetime=f\"{year + 1}-01-31 23:59:59\",\n",
    "            variables=variables,\n",
    "            output_directory=output_dir,\n",
    "            output_filename=os.path.basename(jan_file),\n",
    "            netcdf3_compatible=True\n",
    "        )\n",
    "        success_jan = os.path.exists(jan_file)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ January {year + 1} failed: {e}\")\n",
    "\n",
    "    if success_dec and success_jan:\n",
    "        try:\n",
    "            ds_dec = xr.open_dataset(dec_file)\n",
    "            ds_jan = xr.open_dataset(jan_file)\n",
    "            ds_combined = xr.concat([ds_dec, ds_jan], dim=\"time\")\n",
    "            ds_combined.to_netcdf(output_path)\n",
    "            print(f\"✅ Saved: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to merge/save for {year}: {e}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipping save for {year}: missing one of the months\")\n",
    "\n",
    "    # Cleanup\n",
    "    for f in [dec_file, jan_file]:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2013, 2026):\n",
    "    download_cmems(year, output_dir=\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "dj_uo_series = {}\n",
    "dj_vo_series = {}\n",
    "lat = None\n",
    "lon = None\n",
    "\n",
    "for year in range(2013, 2025):  # up to 2024 inclusive\n",
    "    file_dec = f\"data/copernicus_currents_{year}.nc\"\n",
    "    file_jan = f\"data/copernicus_currents_{year + 1}.nc\"\n",
    "\n",
    "    if not (os.path.exists(file_dec) and os.path.exists(file_jan)):\n",
    "        print(f\"⚠️ Skipping year {year}: missing Dec or Jan file.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        ds_dec = xr.open_dataset(file_dec)\n",
    "        ds_dec = ds_dec.where(ds_dec['time'].dt.month == 12, drop=True)\n",
    "\n",
    "        ds_jan = xr.open_dataset(file_jan)\n",
    "        ds_jan = ds_jan.where(ds_jan['time'].dt.month == 1, drop=True)\n",
    "\n",
    "        ds_dj = xr.concat([ds_dec, ds_jan], dim=\"time\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to open/filter DJ data for {year}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if lat is None:\n",
    "        lat = ds_dj.latitude.values\n",
    "        lon = ds_dj.longitude.values\n",
    "\n",
    "    for i in range(len(lat)):\n",
    "        for j in range(len(lon)):\n",
    "            try:\n",
    "                key = (i, j)\n",
    "                u_vals = ds_dj['uo'][:, i, j].values\n",
    "                v_vals = ds_dj['vo'][:, i, j].values\n",
    "\n",
    "                if np.isnan(u_vals).all() or np.isnan(v_vals).all():\n",
    "                    continue\n",
    "\n",
    "                dj_uo_series.setdefault(key, []).append(np.nanmean(u_vals))\n",
    "                dj_vo_series.setdefault(key, []).append(np.nanmean(v_vals))\n",
    "            except Exception:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load December 2024 and January 2025 actual Copernicus data\n",
    "reader_dec = Reader('data/copernicus_currents_2024.nc')\n",
    "reader_jan = Reader('data/copernicus_currents_2025.nc')\n",
    "\n",
    "# Initialize OceanDrift model\n",
    "o = OceanDrift(loglevel=20)\n",
    "o.add_reader([reader_dec, reader_jan])  # add both readers\n",
    "\n",
    "# Nurdle properties\n",
    "nurdle_diameter = 0.0035  # meters\n",
    "nurdle_density = 980      # kg/m^3\n",
    "total_mass = 740000       # kg\n",
    "\n",
    "particle_volume = (4/3) * np.pi * (nurdle_diameter/2)**3\n",
    "particle_mass = nurdle_density * particle_volume\n",
    "simulated_particles = 2000\n",
    "\n",
    "print(f\"Simulating {simulated_particles} particles with total mass {total_mass} kg\")\n",
    "\n",
    "# Seed region around central Ross Sea\n",
    "seed_lons = np.random.uniform(169.5, 170.5, simulated_particles)\n",
    "seed_lats = np.random.uniform(-75.5, -74.5, simulated_particles)\n",
    "\n",
    "# Seed particles on December 1, 2024\n",
    "o.seed_elements(\n",
    "    lon=seed_lons,\n",
    "    lat=seed_lats,\n",
    "    time=datetime(2024, 12, 1),\n",
    ")\n",
    "\n",
    "# Run simulation through January 2025\n",
    "o.run(end_time=datetime(2025, 1, 31), time_step=3600, time_step_output=86400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38283bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.plot(fast=True, legend=True, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6693f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.animation(\n",
    "    filename=\"nurdle_dispersion_dec_2024_jan_2025.mp4\",\n",
    "    show_elements=True,\n",
    "    show_trajectory=True,\n",
    "    marker_size=2,\n",
    "    dpi=150,\n",
    "    fast=True,\n",
    "    show_time=True,\n",
    "    show_legend=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9124877",
   "metadata": {},
   "source": [
    "## WORK IN PROGRESS BELOW!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86acb0bb",
   "metadata": {},
   "source": [
    "### ARIMA model for December-January currents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine all available NetCDF files from 2013–2025\n",
    "data_dir = \"data\"\n",
    "all_files = sorted(glob.glob(os.path.join(data_dir, \"copernicus_currents_*.nc\")))\n",
    "ds_list = [xr.open_dataset(f) for f in all_files if os.path.exists(f)]\n",
    "combined = xr.concat(ds_list, dim=\"time\")\n",
    "uo, vo = combined[\"uo\"], combined[\"vo\"]\n",
    "\n",
    "# Forecast shape: (62, lat, lon)\n",
    "forecast_days = 62\n",
    "lat_len, lon_len = uo.shape[1], uo.shape[2]\n",
    "forecast_arima_dec_2025_jan_2026 = {\"uo\": np.zeros((forecast_days, lat_len, lon_len)),\n",
    "                                    \"vo\": np.zeros((forecast_days, lat_len, lon_len))}\n",
    "\n",
    "def arima_forecast_3d(component):\n",
    "    result = np.full((forecast_days, lat_len, lon_len), np.nan)\n",
    "    for i in range(lat_len):\n",
    "        for j in range(lon_len):\n",
    "            series = component[:, i, j].values\n",
    "            if np.any(np.isnan(series)):\n",
    "                continue\n",
    "            try:\n",
    "                model = ARIMA(series, order=(1, 0, 0)).fit()\n",
    "                forecast = model.forecast(steps=forecast_days)\n",
    "                result[:, i, j] = forecast\n",
    "            except:\n",
    "                continue\n",
    "    return result\n",
    "\n",
    "forecast_arima_dec_2025_jan_2026[\"uo\"] = arima_forecast_3d(uo)\n",
    "forecast_arima_dec_2025_jan_2026[\"vo\"] = arima_forecast_3d(vo)\n",
    "\n",
    "time = pd.date_range(\"2025-12-01\", periods=62)\n",
    "lat = np.linspace(-75, -70, forecast_arima_dec_2025_jan_2026[\"uo\"].shape[1])\n",
    "lon = np.linspace(160, 170, forecast_arima_dec_2025_jan_2026[\"uo\"].shape[2])\n",
    "\n",
    "# Save ARIMA forecast\n",
    "ds_arima = xr.Dataset(\n",
    "    {\n",
    "        \"uo\": ([\"time\", \"lat\", \"lon\"], forecast_arima_dec_2025_jan_2026[\"uo\"]),\n",
    "        \"vo\": ([\"time\", \"lat\", \"lon\"], forecast_arima_dec_2025_jan_2026[\"vo\"]),\n",
    "    },\n",
    "    coords={\"time\": time, \"lat\": lat, \"lon\": lon}\n",
    ")\n",
    "ds_arima.to_netcdf(\"data/forecast_arima_dec_2025_jan_2026.nc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ab332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load December 2024 and January 2025 actual Copernicus data\n",
    "reader = Reader('data/forecast_arima_dec_2025_jan_2026.nc')\n",
    "\n",
    "# Initialize OceanDrift model\n",
    "o = OceanDrift(loglevel=20)\n",
    "o.add_reader([reader_dec, reader_jan])  # add both readers\n",
    "\n",
    "# Nurdle properties\n",
    "nurdle_diameter = 0.0035  # meters\n",
    "nurdle_density = 980      # kg/m^3\n",
    "total_mass = 740000       # kg\n",
    "\n",
    "particle_volume = (4/3) * np.pi * (nurdle_diameter/2)**3\n",
    "particle_mass = nurdle_density * particle_volume\n",
    "simulated_particles = 2000\n",
    "\n",
    "print(f\"Simulating {simulated_particles} particles with total mass {total_mass} kg\")\n",
    "\n",
    "# Seed region around central Ross Sea\n",
    "seed_lons = np.random.uniform(169.5, 170.5, simulated_particles)\n",
    "seed_lats = np.random.uniform(-75.5, -74.5, simulated_particles)\n",
    "\n",
    "# Seed particles on December 1, 2025\n",
    "o.seed_elements(\n",
    "    lon=seed_lons,\n",
    "    lat=seed_lats,\n",
    "    time=datetime(2025, 12, 1),\n",
    ")\n",
    "\n",
    "# Run simulation through January 2026\n",
    "o.run(end_time=datetime(2026, 1, 31), time_step=3600, time_step_output=86400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f70c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.plot(fast=True, legend=True, filename=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendrift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
